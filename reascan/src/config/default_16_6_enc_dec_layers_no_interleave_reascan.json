{
    "visualization": "True",
    "with_coattention": "True",
    "interleave_self_attn": "False",
    "interleave_order": "NA",

    "v_loc_size": 2, 
    "v_feature_size": 25, 
    
    "vocab_size": 39, 
    "target_vocab_size": 10,
    "max_position_embeddings": 50, 
    "target_max_position_embeddings": 105, 
    
    "num_lang_layers": 0,
    "l_hidden_size": 128, 
    "l_hidden_act": "gelu", 
    "l_num_attention_heads": 8, 
    "l_intermediate_size": 256,
    "l_hidden_dropout_prob": 0.1,
    "t_biattention_id": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 
    "l_attention_probs_dropout_prob": 0.1, 
    
    "num_vis_layers": 0,
    "v_hidden_size": 128, 
    "v_hidden_act": "gelu", 
    "v_num_attention_heads": 8, 
    "v_intermediate_size": 256, 
    "v_hidden_dropout_prob": 0.1,
    "v_biattention_id": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 
    "v_attention_probs_dropout_prob": 0.1, 
    
    "num_decoder_layers": 6,
    "decoder_hidden_size": 128, 
    "decoder_hidden_act": "gelu", 
    "decoder_num_attention_heads": 8, 
    "decoder_intermediate_size": 256, 
    "decoder_hidden_dropout_prob": 0.1,
    
    "bi_hidden_size": 128, 
    "bi_num_attention_heads": 8, 
    "bi_intermediate_size": 256
}